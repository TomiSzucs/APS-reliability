{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version is 1.2.3\n",
      "NumPy version is 1.20.1\n",
      "Statsmodels version is 0.13.2\n",
      "Matplotlib version is 3.3.4\n",
      "Seaborn version is 0.11.1\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Imports done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('Pandas version is %s' % pd.__version__)\n",
    "import numpy as np\n",
    "print('NumPy version is %s' % np.__version__)\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.robust.scale import mad as mad_function\n",
    "print('Statsmodels version is %s' % sm.__version__)\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "print('Matplotlib version is %s' % matplotlib.__version__)\n",
    "import seaborn as sns\n",
    "print('Seaborn version is %s' % sns.__version__)\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "print('Imports done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in and cleaning up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>online ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>TrialIndex</th>\n",
       "      <th>TrialType</th>\n",
       "      <th>StimType</th>\n",
       "      <th>EncodingStimType</th>\n",
       "      <th>rec_trial_key.keys</th>\n",
       "      <th>rec_trial_key.rt</th>\n",
       "      <th>CurrentImage</th>\n",
       "      <th>EncodingImage</th>\n",
       "      <th>...</th>\n",
       "      <th>TripletMemberB</th>\n",
       "      <th>TripletMemberC</th>\n",
       "      <th>CurrentX</th>\n",
       "      <th>CurrentY</th>\n",
       "      <th>Xcoordinate</th>\n",
       "      <th>Ycoordinate</th>\n",
       "      <th>Xcoordinate_lure1</th>\n",
       "      <th>Ycoordinate_lure1</th>\n",
       "      <th>Correct</th>\n",
       "      <th>ResponseNew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>908O1823F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>FOIL</td>\n",
       "      <td>FOIL</td>\n",
       "      <td>j</td>\n",
       "      <td>2.7586</td>\n",
       "      <td>stimuli/fractals/59c.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.304695</td>\n",
       "      <td>0.379784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>908O1823F</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>LURE</td>\n",
       "      <td>ERP</td>\n",
       "      <td>f</td>\n",
       "      <td>1.4135</td>\n",
       "      <td>stimuli/fractals/163c.jpg</td>\n",
       "      <td>stimuli/fractals/163b.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>stimuli/fractals/163a.jpg</td>\n",
       "      <td>stimuli/fractals/163c.jpg</td>\n",
       "      <td>0.376897</td>\n",
       "      <td>0.051308</td>\n",
       "      <td>0.376897</td>\n",
       "      <td>0.051308</td>\n",
       "      <td>0.182213</td>\n",
       "      <td>-0.364402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>908O1823F</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>ERP</td>\n",
       "      <td>j</td>\n",
       "      <td>2.3935</td>\n",
       "      <td>stimuli/fractals/119b.jpg</td>\n",
       "      <td>stimuli/fractals/119b.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>stimuli/fractals/119c.jpg</td>\n",
       "      <td>stimuli/fractals/119a.jpg</td>\n",
       "      <td>-0.205913</td>\n",
       "      <td>0.156378</td>\n",
       "      <td>-0.205913</td>\n",
       "      <td>0.156378</td>\n",
       "      <td>-0.361948</td>\n",
       "      <td>-0.338631</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>908O1823F</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>LURE</td>\n",
       "      <td>ERP</td>\n",
       "      <td>f</td>\n",
       "      <td>1.7771</td>\n",
       "      <td>stimuli/fractals/147a.jpg</td>\n",
       "      <td>stimuli/fractals/147b.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>stimuli/fractals/147c.jpg</td>\n",
       "      <td>stimuli/fractals/147a.jpg</td>\n",
       "      <td>-0.380412</td>\n",
       "      <td>-0.034671</td>\n",
       "      <td>-0.380412</td>\n",
       "      <td>-0.034671</td>\n",
       "      <td>-0.125804</td>\n",
       "      <td>-0.194251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>908O1823F</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>FOIL</td>\n",
       "      <td>FOIL</td>\n",
       "      <td>f</td>\n",
       "      <td>3.4714</td>\n",
       "      <td>stimuli/fractals/161c.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109361</td>\n",
       "      <td>0.393758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    online ID  Group  TrialIndex TrialType StimType EncodingStimType  \\\n",
       "0   908O1823F      0           1       OBJ     FOIL             FOIL   \n",
       "1   908O1823F      0           2       OBJ     LURE              ERP   \n",
       "2   908O1823F      0           3       OBJ   TARGET              ERP   \n",
       "3   908O1823F      0           4       OBJ     LURE              ERP   \n",
       "4   908O1823F      0           5       OBJ     FOIL             FOIL   \n",
       "\n",
       "  rec_trial_key.keys  rec_trial_key.rt               CurrentImage  \\\n",
       "0                  j            2.7586   stimuli/fractals/59c.jpg   \n",
       "1                  f            1.4135  stimuli/fractals/163c.jpg   \n",
       "2                  j            2.3935  stimuli/fractals/119b.jpg   \n",
       "3                  f            1.7771  stimuli/fractals/147a.jpg   \n",
       "4                  f            3.4714  stimuli/fractals/161c.jpg   \n",
       "\n",
       "               EncodingImage  ...             TripletMemberB  \\\n",
       "0                        NaN  ...                        NaN   \n",
       "1  stimuli/fractals/163b.jpg  ...  stimuli/fractals/163a.jpg   \n",
       "2  stimuli/fractals/119b.jpg  ...  stimuli/fractals/119c.jpg   \n",
       "3  stimuli/fractals/147b.jpg  ...  stimuli/fractals/147c.jpg   \n",
       "4                        NaN  ...                        NaN   \n",
       "\n",
       "              TripletMemberC  CurrentX  CurrentY  Xcoordinate  Ycoordinate  \\\n",
       "0                        NaN  0.304695  0.379784          NaN          NaN   \n",
       "1  stimuli/fractals/163c.jpg  0.376897  0.051308     0.376897     0.051308   \n",
       "2  stimuli/fractals/119a.jpg -0.205913  0.156378    -0.205913     0.156378   \n",
       "3  stimuli/fractals/147a.jpg -0.380412 -0.034671    -0.380412    -0.034671   \n",
       "4                        NaN  0.109361  0.393758          NaN          NaN   \n",
       "\n",
       "   Xcoordinate_lure1  Ycoordinate_lure1  Correct  ResponseNew  \n",
       "0                NaN                NaN        1            1  \n",
       "1           0.182213          -0.364402        0            0  \n",
       "2          -0.361948          -0.338631        0            1  \n",
       "3          -0.125804          -0.194251        0            0  \n",
       "4                NaN                NaN        0            0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>online ID</th>\n",
       "      <th>MR ID</th>\n",
       "      <th>Stimuli Table</th>\n",
       "      <th>TrialIndex</th>\n",
       "      <th>TrialType</th>\n",
       "      <th>StimType</th>\n",
       "      <th>EncodingStimType</th>\n",
       "      <th>rec_trial_key.keys</th>\n",
       "      <th>rec_trial_key.rt</th>\n",
       "      <th>CurrentImage</th>\n",
       "      <th>...</th>\n",
       "      <th>TRUE_RGB2_BIN</th>\n",
       "      <th>TRUE_RATING2_BIN</th>\n",
       "      <th>DIST1</th>\n",
       "      <th>DIST1_BIN</th>\n",
       "      <th>DIST2</th>\n",
       "      <th>DIST2_BIN</th>\n",
       "      <th>TRUE_DIST2</th>\n",
       "      <th>TRUE_DIST2_BIN</th>\n",
       "      <th>Correct</th>\n",
       "      <th>ResponseNew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101mTRK21M</td>\n",
       "      <td>275592</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>FOIL</td>\n",
       "      <td>FOIL</td>\n",
       "      <td>c</td>\n",
       "      <td>1.356678</td>\n",
       "      <td>stimuli/fractals/153a.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>foil</td>\n",
       "      <td>foil</td>\n",
       "      <td>3.026812e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>302.681192</td>\n",
       "      <td>3</td>\n",
       "      <td>3.026812e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101mTRK21M</td>\n",
       "      <td>275592</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>LURE</td>\n",
       "      <td>ERP</td>\n",
       "      <td>b</td>\n",
       "      <td>1.532706</td>\n",
       "      <td>stimuli/fractals/25b.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>292.101183</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101mTRK21M</td>\n",
       "      <td>275592</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>ERP</td>\n",
       "      <td>c</td>\n",
       "      <td>1.720454</td>\n",
       "      <td>stimuli/fractals/62c.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>target</td>\n",
       "      <td>target</td>\n",
       "      <td>2.842171e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>306.414435</td>\n",
       "      <td>3</td>\n",
       "      <td>2.842171e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101mTRK21M</td>\n",
       "      <td>275592</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>LURE</td>\n",
       "      <td>ERP</td>\n",
       "      <td>b</td>\n",
       "      <td>1.995551</td>\n",
       "      <td>stimuli/fractals/73b.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>5.684342e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>259.168591</td>\n",
       "      <td>2</td>\n",
       "      <td>5.684342e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101mTRK21M</td>\n",
       "      <td>275592</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>FOIL</td>\n",
       "      <td>FOIL</td>\n",
       "      <td>c</td>\n",
       "      <td>1.295759</td>\n",
       "      <td>stimuli/fractals/108c.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>foil</td>\n",
       "      <td>foil</td>\n",
       "      <td>4.308871e+02</td>\n",
       "      <td>4</td>\n",
       "      <td>430.887072</td>\n",
       "      <td>4</td>\n",
       "      <td>4.308871e+02</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    online ID   MR ID  Stimuli Table  TrialIndex TrialType StimType  \\\n",
       "0  101mTRK21M  275592              2           1       OBJ     FOIL   \n",
       "1  101mTRK21M  275592              2           2       OBJ     LURE   \n",
       "2  101mTRK21M  275592              2           3       OBJ   TARGET   \n",
       "3  101mTRK21M  275592              2           4       OBJ     LURE   \n",
       "4  101mTRK21M  275592              2           5       OBJ     FOIL   \n",
       "\n",
       "  EncodingStimType rec_trial_key.keys  rec_trial_key.rt  \\\n",
       "0             FOIL                  c          1.356678   \n",
       "1              ERP                  b          1.532706   \n",
       "2              ERP                  c          1.720454   \n",
       "3              ERP                  b          1.995551   \n",
       "4             FOIL                  c          1.295759   \n",
       "\n",
       "                CurrentImage  ... TRUE_RGB2_BIN TRUE_RATING2_BIN  \\\n",
       "0  stimuli/fractals/153a.jpg  ...          foil             foil   \n",
       "1   stimuli/fractals/25b.jpg  ...        medium             high   \n",
       "2   stimuli/fractals/62c.jpg  ...        target           target   \n",
       "3   stimuli/fractals/73b.jpg  ...          high           medium   \n",
       "4  stimuli/fractals/108c.jpg  ...          foil             foil   \n",
       "\n",
       "          DIST1 DIST1_BIN       DIST2  DIST2_BIN    TRUE_DIST2  \\\n",
       "0  3.026812e+02         3  302.681192          3  3.026812e+02   \n",
       "1  0.000000e+00         0  292.101183          2  0.000000e+00   \n",
       "2  2.842171e-14         0  306.414435          3  2.842171e-14   \n",
       "3  5.684342e-14         0  259.168591          2  5.684342e-14   \n",
       "4  4.308871e+02         4  430.887072          4  4.308871e+02   \n",
       "\n",
       "   TRUE_DIST2_BIN  Correct  ResponseNew  \n",
       "0               3        1            1  \n",
       "1               0        0            0  \n",
       "2               0        0            1  \n",
       "3               0        0            0  \n",
       "4               4        1            1  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Read in data ###\n",
    "data_mr_young = pd.read_excel('miniTRK_APS_Recognition_Trial-by-Trial_Data.xlsx')\n",
    "indeces = data_mr_young[data_mr_young['Correct'] == -1].index  # -1 in 'Correct' column denotes missing response\n",
    "data_mr_young = data_mr_young.drop(indeces, axis=0)\n",
    "\n",
    "data_online = pd.read_excel('longTRK_APS_Recognition_Trial-by-Trial_Data.xlsx')\n",
    "data_online.rename(columns={'Online ID':'online ID'}, inplace=True) # Renaming for consistency\n",
    "\n",
    "# Splitting young and old online data\n",
    "data_online_young = data_online[data_online['Group']==1]\n",
    "data_online_old = data_online[data_online['Group']==0]\n",
    "data_online_old = data_online_old.replace(\"410O824F)\", \"410O824F\")\n",
    "data_list = [data_mr_young, data_online_young, data_online_old, data_online]\n",
    "data_names = ['data_mr_young', 'data_online_young', 'data_online_old', 'data_online']\n",
    "display(data_online.head(), data_mr_young.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for preprocessing ###\n",
    "\n",
    "def filter_completed(data, criteria=None, id_var='online ID'):\n",
    "    \"\"\"\n",
    "    Filter out participants having less completed trials than criterion. Print number of deleted participants.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dataframe\n",
    "    criteria: float or None\n",
    "        Minimum number of trials for a participant to be included\n",
    "    id_var: str\n",
    "        Name of column containing participant names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        Filtered data\n",
    "\n",
    "    \"\"\"\n",
    "    participant_completed = [name for name in data[id_var].unique() if (data[data[id_var]==name][id_var].value_counts() >= criteria).all()]\n",
    "    difference = len(data[id_var].unique()) - len(participant_completed)\n",
    "    print('Deleted participants:', difference)\n",
    "\n",
    "    data = data[data[id_var].isin(participant_completed)]\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation ###\n",
    "\n",
    "# Filter out participants with more than 10% missing trials\n",
    "for i in range(len(data_list)):\n",
    "    data = data_list[i]\n",
    "    data_list[i] = filter_completed(data, 144*0.9)\n",
    "\n",
    "# Combined dataframe for plotting\n",
    "for i in range(len(data_list)):\n",
    "    df = data_list[i]\n",
    "    df.loc[:,'data_set'] = data_names[i]\n",
    "    data_list[i] = df\n",
    "data_all = pd.concat([data_list[i] for i in range(len(data_list))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating effect sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_correction(proportion, all):\n",
    "    \"\"\"\n",
    "    Perform edge-correction to avoid infinite values in d-prime calculations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    proportion : float\n",
    "        Quantity to check.\n",
    "    all: float\n",
    "        Quantity to use in correction, e.g. hits + misses, false alarms + correct rejections, etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \n",
    "    \"\"\"\n",
    "    # Should we exclude participants instead?\n",
    "    if proportion >= 1:\n",
    "        proportion = 1 - (0.5/all)\n",
    "    elif proportion <= 0:\n",
    "        proportion = 0.5/all\n",
    "    return proportion\n",
    "\n",
    "def discrimination_calculator(data, id_var='online ID', stimtype_var='StimType', response_var='ResponseNew'):\n",
    "    \"\"\"\n",
    "    Compute d-prime as a measure of discrimination in the APS task. D-prime is calculated as the difference in \n",
    "    the z-transformed proportions of 'old' answers to 'target' stimuli and 'old' answers to 'lure' stimuli.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "        Long format dataframe with a column for subject, stimulus type and response (new/old).\n",
    "    id_var : str\n",
    "        Name of column containing participant names.\n",
    "    stimtype_var : str\n",
    "        Name of column containing stimulus type in trial.\n",
    "    response_var : str\n",
    "        Name of column containing responses. 'New' should be coded as 1, 'old' should be coded as 0.\n",
    "    filters : list of str\n",
    "        List of regressors to include in d-prime calculation for noise filtering.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        Dataframe containing a column for participant ID and a column for their respective d-prime values.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # TODO Is edge-correction the best solution to deal with infs?\n",
    "    # Edge-correction: https://lindeloev.net/calculating-d-in-python-and-php/\n",
    "    # adjusted ratios: https://github.com/neuropsychology/psycho.R/blob/master/R/dprime.R\n",
    "    # or just returning nan.\n",
    "\n",
    "    discrimination_df = pd.DataFrame(columns=[id_var, 'd_prime', 'p_old_target', 'p_old_lure']) # Setup output dataframe\n",
    "    for id in data[id_var].unique():\n",
    "        # Looping through each participant's data\n",
    "        data_participant = data[data[id_var]==id]\n",
    "        all_target = len(data_participant[data_participant[stimtype_var]=='TARGET'])\n",
    "        all_lure = len(data_participant[data_participant[stimtype_var]=='LURE'])\n",
    "\n",
    "        # Calculate proportion of old-target answers to all answers and old-lure answers to all answers\n",
    "        p_old_target = len(data_participant[(data_participant[response_var]==0) & (data_participant[stimtype_var]=='TARGET')]) / all_target\n",
    "        p_old_lure = len(data_participant[(data_participant[response_var]==0) & (data_participant[stimtype_var]=='LURE')]) / all_lure\n",
    "        \n",
    "        # Avoiding infinite values by edge-correction\n",
    "        p_old_target = edge_correction(p_old_target, all_target)\n",
    "        p_old_lure = edge_correction(p_old_lure, all_lure)\n",
    "                \n",
    "        discrimination = stats.norm.ppf(p_old_target) - stats.norm.ppf(p_old_lure)\n",
    "        discrimination_df = discrimination_df.append({id_var:id, 'd_prime':discrimination, 'p_old_target':p_old_target,'p_old_lure':p_old_lure}, ignore_index=True)\n",
    "    \n",
    "    return discrimination_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Even-odd split-half reliability with Spearman-Brown correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correl_ci(coefficient, CI, data):\n",
    "    \"\"\"\n",
    "    Calculate confidence interval of correlation coefficient using Fisher's Z-transform.\n",
    "    \n",
    "    Paramters\n",
    "    ----------\n",
    "    coefficient: float\n",
    "        The correlation coefficient.\n",
    "    CI: {90, 95, 99}\n",
    "        The desired confidence level.\n",
    "    data: dataframe\n",
    "        The dataframe from which the correlation coefficient was calculated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        First element is the correlation coefficient, second element is the lower bound\n",
    "        of the CI and the third element is the upper bound of the CI.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #CI transform\n",
    "    if CI == 90:\n",
    "        z_CI = 1.645\n",
    "    elif CI == 95:\n",
    "        z_CI = 1.96\n",
    "    elif CI == 99:\n",
    "        z_CI = 2.576\n",
    "    \n",
    "    #Calculate\n",
    "    datan = len(data)\n",
    "    z_r = 0.5 * np.log((1+coefficient) / (1-coefficient))\n",
    "    z_low = z_r - z_CI * np.sqrt(1.0/(datan-3))\n",
    "    z_high = z_r + z_CI * np.sqrt(1.0/(datan-3))\n",
    "    \n",
    "    #Convert back\n",
    "    r_low = ((np.exp(2 * z_low)) - 1) / ((np.exp(2 * z_low)) + 1)\n",
    "    r_high = ((np.exp(2 * z_high)) - 1) / ((np.exp(2 * z_high)) + 1)\n",
    "\n",
    "    return [coefficient, r_low, r_high]\n",
    "\n",
    "def split_var(length):\n",
    "    \"\"\"\n",
    "    Make a list of given length of alternating 0s and 1s.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    length: int\n",
    "        Length of list\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "\n",
    "    \"\"\"\n",
    "    a = np.empty((length,))\n",
    "    a[::2] = 1\n",
    "    a[1::2] = 0\n",
    "    return a.tolist()\n",
    "\n",
    "def assign_even_odd(data, id_var):\n",
    "    \"\"\"\n",
    "    Split data into even and odd trials for each participant.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dataframe\n",
    "    id_var: string\n",
    "        Name of the column holding participant names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        The data containing even numbered trials\n",
    "    dataframe\n",
    "        The data containing odd numbered trials\n",
    "    dataframe\n",
    "        The original data\n",
    "    \"\"\"\n",
    "    data_sorted = pd.DataFrame()\n",
    "    for participant in data[id_var].unique():\n",
    "        data_participant = data[data[id_var] == participant].sort_values('StimType')  # Stratified even-odd (Pronk, 2021)\n",
    "        splitting_list = split_var(len(data_participant))\n",
    "        data_participant.loc[:,'split_var'] = splitting_list\n",
    "        data_sorted = pd.concat([data_sorted, data_participant])\n",
    "\n",
    "    data_even = data_sorted[data_sorted['split_var']==0]\n",
    "    data_odd = data_sorted[data_sorted['split_var']==1]\n",
    "\n",
    "    return data_even, data_odd, data\n",
    "\n",
    "def splithalf(data, id_var='online ID', nonparametric=False):\n",
    "    \"\"\"\n",
    "    Calculate split-half reliability with and without Spearman-Brown correction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dataframe\n",
    "    id_var: str\n",
    "        Name of the column holding participant names\n",
    "    nonparametric: bool\n",
    "        Calculate Spearman's rank-order correlation if True, Pearson's if False\n",
    "    method: {'regression', 'difference}\n",
    "        See discrimination_calculator for details.\n",
    "    regressors: list of str\n",
    "        See discrimination_calculator for details.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        First element is the uncorrected correlation coefficient, second element is the \n",
    "        lower bound of the CI and the third element is the upper bound of the CI.\n",
    "    list\n",
    "        First element is the Spearman-Brown corrected correlation coefficient, second element\n",
    "        is the lower bound of the CI and the third element is the upper bound of the CI.\n",
    "    list\n",
    "        Difference as percentage of total trials of given type (TARGET and LURE respectively)\n",
    "        between the two halves.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_even, data_odd, data = assign_even_odd(data, id_var)\n",
    "    even_target, odd_target, even_lure, odd_lure = len(data_even[data_even['StimType']=='TARGET']), len(data_odd[data_odd['StimType']=='TARGET']), len(data_even[data_even['StimType']=='LURE']), len(data_odd[data_odd['StimType']=='LURE'])\n",
    "    target_diff, lure_diff = abs(even_target - odd_target) / len(data[data['StimType']=='TARGET']) *100, abs(even_lure - odd_lure) / len(data[data['StimType']=='TARGET']) * 100\n",
    "\n",
    "    discrimination_even = discrimination_calculator(data_even)\n",
    "    discrimination_odd = discrimination_calculator(data_odd)\n",
    "\n",
    "    if nonparametric:\n",
    "        r_raw = stats.spearmanr(discrimination_even['d_prime'], discrimination_odd['d_prime']).correlation\n",
    "    else:\n",
    "        r_raw = np.corrcoef(discrimination_even['d_prime'], discrimination_odd['d_prime'])[0][1]\n",
    "\n",
    "    r_corrected = (2*r_raw) / (1+r_raw)  # Spearman-Brown correction\n",
    "    result_raw = correl_ci(r_raw, 95, data_even)\n",
    "    result_corrected = correl_ci(r_corrected, 95, data_even)\n",
    "    return result_raw, result_corrected, [target_diff, lure_diff]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= OBJ =========================\n",
      "------------------------- data_mr_young -------------------------\n",
      "No filtering\n",
      "Using regressors:  \n",
      "------------------------- data_online_young -------------------------\n",
      "No filtering\n",
      "Using regressors:  \n",
      "------------------------- data_online_old -------------------------\n",
      "No filtering\n",
      "Using regressors:  \n",
      "------------------------- data_online -------------------------\n",
      "No filtering\n",
      "Using regressors:  \n",
      "========================= LOC =========================\n",
      "------------------------- data_mr_young -------------------------\n",
      "No filtering\n",
      "Using regressors:  \n",
      "------------------------- data_online_young -------------------------\n",
      "No filtering\n",
      "Using regressors:  \n",
      "------------------------- data_online_old -------------------------\n",
      "No filtering\n",
      "Using regressors:  \n",
      "------------------------- data_online -------------------------\n",
      "No filtering\n",
      "Using regressors:  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>type</th>\n",
       "      <th>filter</th>\n",
       "      <th>regressor</th>\n",
       "      <th>splithalf</th>\n",
       "      <th>split_half_CI_low</th>\n",
       "      <th>split_half_CI_high</th>\n",
       "      <th>spearman_brown</th>\n",
       "      <th>spearman_brown_CI_low</th>\n",
       "      <th>spearman_brown_CI_high</th>\n",
       "      <th>target_diff (%)</th>\n",
       "      <th>lure_diff (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_mr_young</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "      <td>0.315520</td>\n",
       "      <td>0.258554</td>\n",
       "      <td>0.370298</td>\n",
       "      <td>0.479688</td>\n",
       "      <td>0.430471</td>\n",
       "      <td>0.526062</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.497512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_online_young</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "      <td>0.094855</td>\n",
       "      <td>0.036217</td>\n",
       "      <td>0.152843</td>\n",
       "      <td>0.173275</td>\n",
       "      <td>0.115613</td>\n",
       "      <td>0.229773</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.804290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_online_old</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "      <td>0.015970</td>\n",
       "      <td>-0.028659</td>\n",
       "      <td>0.060535</td>\n",
       "      <td>0.031437</td>\n",
       "      <td>-0.013189</td>\n",
       "      <td>0.075939</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.568475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_online</td>\n",
       "      <td>OBJ</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "      <td>0.091540</td>\n",
       "      <td>0.056178</td>\n",
       "      <td>0.126673</td>\n",
       "      <td>0.167727</td>\n",
       "      <td>0.132975</td>\n",
       "      <td>0.202067</td>\n",
       "      <td>0.392927</td>\n",
       "      <td>0.654879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_mr_young</td>\n",
       "      <td>LOC</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "      <td>0.117001</td>\n",
       "      <td>0.055190</td>\n",
       "      <td>0.177918</td>\n",
       "      <td>0.209491</td>\n",
       "      <td>0.149224</td>\n",
       "      <td>0.268208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data_online_young</td>\n",
       "      <td>LOC</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.129573</td>\n",
       "      <td>0.242905</td>\n",
       "      <td>0.314882</td>\n",
       "      <td>0.260998</td>\n",
       "      <td>0.366810</td>\n",
       "      <td>0.446030</td>\n",
       "      <td>0.624442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data_online_old</td>\n",
       "      <td>LOC</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "      <td>-0.052066</td>\n",
       "      <td>-0.096774</td>\n",
       "      <td>-0.007147</td>\n",
       "      <td>-0.109851</td>\n",
       "      <td>-0.154026</td>\n",
       "      <td>-0.065238</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>1.907216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data_online</td>\n",
       "      <td>LOC</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "      <td>0.049806</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.085335</td>\n",
       "      <td>0.094886</td>\n",
       "      <td>0.059407</td>\n",
       "      <td>0.130126</td>\n",
       "      <td>0.228683</td>\n",
       "      <td>1.437439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                data type filter regressor  splithalf  split_half_CI_low  \\\n",
       "0      data_mr_young  OBJ   none             0.315520           0.258554   \n",
       "1  data_online_young  OBJ   none             0.094855           0.036217   \n",
       "2    data_online_old  OBJ   none             0.015970          -0.028659   \n",
       "3        data_online  OBJ   none             0.091540           0.056178   \n",
       "4      data_mr_young  LOC   none             0.117001           0.055190   \n",
       "5  data_online_young  LOC   none             0.186860           0.129573   \n",
       "6    data_online_old  LOC   none            -0.052066          -0.096774   \n",
       "7        data_online  LOC   none             0.049806           0.014151   \n",
       "\n",
       "   split_half_CI_high  spearman_brown  spearman_brown_CI_low  \\\n",
       "0            0.370298        0.479688               0.430471   \n",
       "1            0.152843        0.173275               0.115613   \n",
       "2            0.060535        0.031437              -0.013189   \n",
       "3            0.126673        0.167727               0.132975   \n",
       "4            0.177918        0.209491               0.149224   \n",
       "5            0.242905        0.314882               0.260998   \n",
       "6           -0.007147       -0.109851              -0.154026   \n",
       "7            0.085335        0.094886               0.059407   \n",
       "\n",
       "   spearman_brown_CI_high  target_diff (%)  lure_diff (%)  \n",
       "0                0.526062         0.298507       0.497512  \n",
       "1                0.229773         0.268097       0.804290  \n",
       "2                0.075939         0.465116       0.568475  \n",
       "3                0.202067         0.392927       0.654879  \n",
       "4                0.268208         0.000000       0.903614  \n",
       "5                0.366810         0.446030       0.624442  \n",
       "6               -0.065238         0.103093       1.907216  \n",
       "7                0.130126         0.228683       1.437439  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Looping through each sample and condition ###\n",
    "trial_types = ['OBJ', 'LOC']\n",
    "result_even_odd = pd.DataFrame(columns=['data', 'type', 'splithalf', 'split_half_CI_low', 'split_half_CI_high', 'spearman_brown', 'spearman_brown_CI_low', 'spearman_brown_CI_high', 'target_diff (%)', 'lure_diff (%)'])\n",
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    for trial_type in trial_types:\n",
    "        print('='*25, trial_type, '='*25)\n",
    "        for data, data_name in zip(data_list, data_names):\n",
    "            print(data_name)\n",
    "            data_dropped = data[['online ID', 'rec_trial_key.rt', 'TrialType', 'StimType', 'ResponseNew']].dropna()\n",
    "            data_temp = data_dropped[(data_dropped['StimType']=='TARGET')|(data_dropped['StimType']=='LURE')]\n",
    "            even_odd_result, corrected_result, difference = splithalf(data_temp[data_temp['TrialType']==trial_type], nonparametric=False)\n",
    "            result_even_odd.loc[len(result_even_odd.index)] = [data_name, trial_type, even_odd_result[0], even_odd_result[1], even_odd_result[2], corrected_result[0], corrected_result[1], corrected_result[2], difference[0], difference[1]]\n",
    "            \n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "display(result_even_odd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampled_splithalf(data, id_var='online ID', nonparametric=False, level='participant', type='monte_carlo', i=None):\n",
    "    \"\"\"\n",
    "    Draw two samples with replacement from the data and calculate the reliabiltiy as the correlation between the \n",
    "    participant effect sizes in the two samples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dataframe\n",
    "    id_var: str\n",
    "        Name of the column holding participant names\n",
    "    nonparametric: bool\n",
    "        Calculate Spearman's rank-order correlation if True, Pearson's if False\n",
    "    level: {'participant', 'trial'}\n",
    "        Level of resampling. If 'participant', resample participants but not trials, if 'trial', resample trials but not participants.\n",
    "    type: {'monte_carlo', 'permutation'}\n",
    "        If 'monte_carlo', sample with replacement with frac=1.0, if 'premutation' sample without replacement with farc=0.5 and use Spearman-Brown correction.\n",
    "    i: int\n",
    "        Number of iteration.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The calculated reliabiltiy as a correlation coefficient\n",
    "    dataframe\n",
    "        The participant effect sizes from the two samples\n",
    "    \"\"\"\n",
    "    if type == 'monte_carlo':\n",
    "        resample_frac = 1.0\n",
    "        replacement = True\n",
    "    elif type == 'permutation':\n",
    "        resample_frac = 0.5\n",
    "        replacement = False\n",
    "\n",
    "    if level == 'trial':\n",
    "        # Resampling by participant and stimulus type\n",
    "        data_1, data_2 = pd.DataFrame(columns=data.columns), pd.DataFrame(columns=data.columns)\n",
    "        for participant in data[id_var].unique():\n",
    "            data_participant = data[data[id_var] == participant]\n",
    "            if type == 'monte_carlo':\n",
    "                data_1_target = data_participant[data_participant['StimType']=='TARGET'].sample(frac=resample_frac, replace=replacement)\n",
    "                data_1_lure = data_participant[data_participant['StimType']=='LURE'].sample(frac=resample_frac, replace=replacement)\n",
    "                data_2_target = data_participant[data_participant['StimType']=='TARGET'].sample(frac=resample_frac, replace=replacement)\n",
    "                data_2_lure = data_participant[data_participant['StimType']=='LURE'].sample(frac=resample_frac, replace=replacement)\n",
    "            elif type == 'permutation':\n",
    "                data_1_target = data_participant[data_participant['StimType']=='TARGET'].sample(frac=resample_frac, replace=replacement)\n",
    "                data_1_lure = data_participant[data_participant['StimType']=='LURE'].sample(frac=resample_frac, replace=replacement)\n",
    "                data_2_target = data_participant[data_participant['StimType']=='TARGET'].drop(data_1_target.index)\n",
    "                data_2_lure = data_participant[data_participant['StimType']=='LURE'].drop(data_1_lure.index)\n",
    "            data_1 = pd.concat([data_1, data_1_target, data_1_lure])\n",
    "            data_2 = pd.concat([data_2, data_2_target, data_2_lure])\n",
    "        discrimination_1 = discrimination_calculator(data_1)\n",
    "        discrimination_2 = discrimination_calculator(data_2)\n",
    "    \n",
    "    elif level == 'participant':\n",
    "        data_1, data_2, data = assign_even_odd(data, id_var)\n",
    "        discrimination_even = discrimination_calculator(data_1)\n",
    "        discrimination_odd = discrimination_calculator(data_2)\n",
    "        discrimination_1 = discrimination_even.sample(frac=resample_frac, replace=replacement)\n",
    "        discrimination_2 = pd.DataFrame()\n",
    "        for name in discrimination_1[id_var]:\n",
    "            discrimination_2 = pd.concat([discrimination_2, discrimination_odd[discrimination_odd[id_var]==name]])\n",
    "        \n",
    "    \n",
    "    # Gathering participant effect sizes\n",
    "    discrimination_1.loc[:,'iteration'] = i\n",
    "    discrimination_2.loc[:,'iteration'] = i\n",
    "    discrimination_1.loc[:,'e_o'] = 1\n",
    "    discrimination_2.loc[:,'e_o'] = 2\n",
    "    discrimination = pd.concat([discrimination_1, discrimination_2])\n",
    "\n",
    "    # Calculating split-half reliability with Pearson or Spearman\n",
    "    if nonparametric:\n",
    "        reliability = stats.spearmanr(discrimination_1['d_prime'], discrimination_2['d_prime']).correlation\n",
    "    else:\n",
    "        reliability = np.corrcoef(discrimination_1['d_prime'], discrimination_2['d_prime'])[0][1]\n",
    "\n",
    "    if type == 'permutation':\n",
    "        reliability = (2*reliability) / (1+reliability)  # Spearman-Brown correction\n",
    "\n",
    "    return reliability, discrimination\n",
    "\n",
    "\n",
    "def bootstrap_loop(n, data, level='participant', type = 'monte_carlo'):\n",
    "    \"\"\"\n",
    "    Loop resampled_splithalf() n times to perform bootstrapping.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Number of resamplings to perform\n",
    "    data: dataframe\n",
    "        Dataframe to analyse\n",
    "    level: {'participant', 'trial'}\n",
    "        Level of resampling. If 'participant', resample participants but not trials, if 'trial', resample trials but not participants.\n",
    "    type: {'monte_carlo', 'permutation'}\n",
    "        If 'monte_carlo', sample with replacement with frac=1.0, if 'premutation' sample without replacement with farc=0.5 and use Spearman-Brown correction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The correlation coefficients from each resampling\n",
    "    dataframe\n",
    "        The participant effect sizes from all resamplings\n",
    "    \"\"\"\n",
    "    reliability_distribution = []\n",
    "    effect_sizes = pd.DataFrame(columns=['online ID', 'd_prime', 'p_old_target', 'p_old_lure', 'iteration', 'e_o'])\n",
    "    for i in range(n):\n",
    "        print(i, end=\" \")\n",
    "        reliability, discrimination = resampled_splithalf(data, id_var='online ID', nonparametric=False, level=level, type=type, i=i)\n",
    "        reliability_distribution.append(reliability)\n",
    "        effect_sizes = pd.concat([effect_sizes, discrimination])\n",
    "    return reliability_distribution, effect_sizes\n",
    "\n",
    "\n",
    "def bootstrapping_analyses(n, level='participant', type = 'monte_carlo', data_list=data_list, data_names=data_names):\n",
    "    \"\"\"\n",
    "    Run boostrap_loop() on all samples and conditions. Gather results into dataframes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Number of resamplings to perform\n",
    "    level: {'participant', 'trial'}\n",
    "        Level of resampling. If 'participant', resample participants but not trials, if 'trial', resample trials but not participants.\n",
    "    type: {'monte_carlo', 'permutation'}\n",
    "        If 'monte_carlo', sample with replacement with frac=1.0, if 'premutation' sample without replacement with farc=0.5 and use Spearman-Brown correction.\n",
    "    data_list: list of dataframes\n",
    "        List of dataframes to analyize.\n",
    "    data_names: list of str\n",
    "        Lists of the names of the dataframes analyized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        Participant effect sizes labeled by data_set and condition\n",
    "    dataframe\n",
    "        Reliability results as correlation coefficients labeled by data_set and condition\n",
    "    \"\"\"\n",
    "    trial_types = ['OBJ', 'LOC']\n",
    "    reliability_distribution = pd.DataFrame(columns=['r', 'data_set', 'trial_type'])\n",
    "    effect_size_distribution = pd.DataFrame(columns=['online ID', 'd_prime', 'iteration', 'e_o', 'data_set', 'trial_type'])\n",
    "    with pd.option_context('mode.chained_assignment', None):\n",
    "        for trial_type in trial_types:\n",
    "            for df, data_name in zip(data_list, data_names):\n",
    "                data = df[df['TrialType']==trial_type]\n",
    "                print('\\n', 'Resampling: ', trial_type, data_name)\n",
    "                reliability_list, effect_sizes = bootstrap_loop(n, data, level=level, type=type)\n",
    "                reliability_df = pd.DataFrame(reliability_list, columns=['r'])\n",
    "                reliability_df['data_set'] = data_name\n",
    "                reliability_df['trial_type'] = trial_type\n",
    "                effect_sizes['data_set'] = data_name\n",
    "                effect_sizes['trial_type'] = trial_type\n",
    "\n",
    "                effect_size_distribution = pd.concat([effect_size_distribution, effect_sizes[['online ID', 'd_prime','iteration', 'e_o', 'data_set', 'trial_type']]])\n",
    "                reliability_distribution = pd.concat([reliability_distribution, reliability_df])\n",
    "    # display(effect_size_distribution,reliability_distribution)\n",
    "    return effect_size_distribution, reliability_distribution\n",
    "\n",
    "# Run bootstrapping\n",
    "effect_size_distribution, reliability_distribution = bootstrapping_analyses(n=10, level='participant', type='permutation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_size_agg(data):\n",
    "    \"\"\"\n",
    "    Calculate mean participant effect sizes and percentile bootsrapping 95% CIs for each participant in each dataset and condition.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dataframe\n",
    "        Dataframe including all effect sizes for all participants calculated in all resamples. Needs 'online ID', 'data_set and 'trial_type' columns \n",
    "        denoting participant names, the dataset used for calculation and the condition, respectively.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        Dataframe containing mean effect size and its 95% bootstrapped CI lower and upper bounds as values and as differences from the mean, \n",
    "        as well as the data_set and trial_type.\n",
    "    \"\"\"\n",
    "    effect_size_summary = pd.DataFrame(columns=['online ID', 'd_mean', 'd_lower','d_higher', 'd_lower_diff', 'd_higher_diff', 'data_set', 'trial_type'])\n",
    "    for data_name in data['data_set'].unique():\n",
    "        for trial_type in data['trial_type'].unique():\n",
    "            data_temp = data[(data['data_set']==data_name)&(data['trial_type']==trial_type)]\n",
    "            summary_temp = pd.DataFrame()\n",
    "            summary_temp['online ID'] = data_temp['online ID'].unique()\n",
    "            summary_temp['ID_num'] = [j for i, j in zip(summary_temp['online ID'], range(len(summary_temp['online ID'])))]\n",
    "\n",
    "            summary_temp['d_mean'] = [np.mean(data_temp[data_temp['online ID']==name]['d_prime']) for name in data_temp['online ID'].unique()]\n",
    "            summary_temp['d_lower'] = [np.percentile(data_temp[data_temp['online ID']==name]['d_prime'],2.5) for name in data_temp['online ID'].unique()]\n",
    "            summary_temp['d_higher'] = [np.percentile(data_temp[data_temp['online ID']==name]['d_prime'],97.5) for name in data_temp['online ID'].unique()]\n",
    "\n",
    "            summary_temp['d_lower_diff'] = summary_temp['d_mean'] - summary_temp['d_lower']\n",
    "            summary_temp['d_higher_diff'] = summary_temp['d_higher'] - summary_temp['d_mean']\n",
    "            summary_temp['data_set'] = data_name\n",
    "            summary_temp['trial_type'] = trial_type\n",
    "            effect_size_summary = pd.concat([effect_size_summary, summary_temp])\n",
    "\n",
    "    return effect_size_summary\n",
    "\n",
    "def bs_reliability_agg(data):\n",
    "    \"\"\"\n",
    "    Calculate mean reliability, its percentile bootstrapping 95% CI for each dataset and condition used in the analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dataframe\n",
    "        Needs 'r', 'data_set and 'trial_type' columns denoting measured reliability, the dataset used for calculation and \n",
    "        the condition, respectively.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        Dataframe containing mean reliability and its 95% bootstrapped CI lower and upper bounds as values and as differences from the mean, \n",
    "        as well as the data_set and trial_type.\n",
    "    \"\"\"\n",
    "    reliability_summary = pd.DataFrame(columns=['r_mean', 'r_lower','r_higher', 'r_lower_diff', 'r_higher_diff', 'data_set', 'trial_type'])\n",
    "    for data_name in data['data_set'].unique():\n",
    "        for trial_type in data['trial_type'].unique():\n",
    "            data_temp = data[(data['data_set']==data_name)&(data['trial_type']==trial_type)]\n",
    "            summary_temp = pd.DataFrame()\n",
    "\n",
    "            summary_temp['r_mean'] = [np.mean(data_temp['r'])]\n",
    "            summary_temp['r_lower'] = [np.percentile(data_temp['r'],2.5)]\n",
    "            summary_temp['r_higher'] = [np.percentile(data_temp['r'],97.5)]\n",
    "\n",
    "            summary_temp['r_lower_diff'] = summary_temp['r_mean'] - summary_temp['r_lower']\n",
    "            summary_temp['r_higher_diff'] = summary_temp['r_higher'] - summary_temp['r_mean']\n",
    "            summary_temp['data_set'] = data_name\n",
    "            summary_temp['trial_type'] = trial_type\n",
    "            reliability_summary = pd.concat([reliability_summary, summary_temp])\n",
    "\n",
    "    return reliability_summary\n",
    "\n",
    "# Run summary functions\n",
    "effect_size_summary = effect_size_agg(effect_size_distribution)\n",
    "reliability_summary = bs_reliability_agg(reliability_distribution)\n",
    "effect_size_summary_1 = effect_size_agg(effect_size_distribution[effect_size_distribution['e_o']==1])\n",
    "effect_size_summary_2 = effect_size_agg(effect_size_distribution[effect_size_distribution['e_o']==2])\n",
    "# display(effect_size_summary.head(), effect_size_summary_1.head(), effect_size_summary_2.head(), reliability_summary)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participan effect sizes and CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data_mr_young', 'data_online_young', 'data_online_old',\n",
       "       'data_online'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of participant CIs containing 0:  89.47368421052632 %\n",
      "In different samples:\n",
      "In data_mr_young :  84.52380952380952 %\n",
      "In data_online_young :  81.91489361702128 %\n",
      "In data_online_old :  96.34146341463415 %\n",
      "In different task versions:\n",
      "In OBJ :  90.05847953216374 %\n",
      "In LOC :  88.88888888888889 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_type</th>\n",
       "      <th>data_frame</th>\n",
       "      <th>CI overlap (%)</th>\n",
       "      <th>point estimate overlap (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJ</td>\n",
       "      <td>data_mr_young</td>\n",
       "      <td>98.838560</td>\n",
       "      <td>79.790941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OBJ</td>\n",
       "      <td>data_online_young</td>\n",
       "      <td>99.537465</td>\n",
       "      <td>83.811286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OBJ</td>\n",
       "      <td>data_online_old</td>\n",
       "      <td>99.789220</td>\n",
       "      <td>82.821439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OBJ</td>\n",
       "      <td>data_online</td>\n",
       "      <td>99.370155</td>\n",
       "      <td>81.474079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOC</td>\n",
       "      <td>data_mr_young</td>\n",
       "      <td>97.328688</td>\n",
       "      <td>70.615563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOC</td>\n",
       "      <td>data_online_young</td>\n",
       "      <td>98.427382</td>\n",
       "      <td>77.983349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LOC</td>\n",
       "      <td>data_online_old</td>\n",
       "      <td>97.711533</td>\n",
       "      <td>81.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOC</td>\n",
       "      <td>data_online</td>\n",
       "      <td>97.771318</td>\n",
       "      <td>78.258236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trial_type         data_frame  CI overlap (%)  point estimate overlap (%)\n",
       "0        OBJ      data_mr_young       98.838560                   79.790941\n",
       "1        OBJ  data_online_young       99.537465                   83.811286\n",
       "2        OBJ    data_online_old       99.789220                   82.821439\n",
       "3        OBJ        data_online       99.370155                   81.474079\n",
       "4        LOC      data_mr_young       97.328688                   70.615563\n",
       "5        LOC  data_online_young       98.427382                   77.983349\n",
       "6        LOC    data_online_old       97.711533                   81.135200\n",
       "7        LOC        data_online       97.771318                   78.258236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Mean Ci overlap'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "98.60547458926958"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Mean containing point estimate'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "79.35962970483853"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task version</th>\n",
       "      <th>Sample</th>\n",
       "      <th>CI overlap (average %)</th>\n",
       "      <th>Point estimate overlap (average %)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Object version</td>\n",
       "      <td>MRI data (young)</td>\n",
       "      <td>98.84</td>\n",
       "      <td>79.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Object version</td>\n",
       "      <td>Online data (young)</td>\n",
       "      <td>99.54</td>\n",
       "      <td>83.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Object version</td>\n",
       "      <td>Online data (old)</td>\n",
       "      <td>99.79</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Object version</td>\n",
       "      <td>Online data (all)</td>\n",
       "      <td>99.37</td>\n",
       "      <td>81.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Location version</td>\n",
       "      <td>MRI data (young)</td>\n",
       "      <td>97.33</td>\n",
       "      <td>70.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Location version</td>\n",
       "      <td>Online data (young)</td>\n",
       "      <td>98.43</td>\n",
       "      <td>77.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Location version</td>\n",
       "      <td>Online data (old)</td>\n",
       "      <td>97.71</td>\n",
       "      <td>81.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Location version</td>\n",
       "      <td>Online data (all)</td>\n",
       "      <td>97.77</td>\n",
       "      <td>78.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Task version               Sample  CI overlap (average %)  \\\n",
       "0    Object version     MRI data (young)                   98.84   \n",
       "1    Object version  Online data (young)                   99.54   \n",
       "2    Object version    Online data (old)                   99.79   \n",
       "3    Object version    Online data (all)                   99.37   \n",
       "4  Location version     MRI data (young)                   97.33   \n",
       "5  Location version  Online data (young)                   98.43   \n",
       "6  Location version    Online data (old)                   97.71   \n",
       "7  Location version    Online data (all)                   97.77   \n",
       "\n",
       "   Point estimate overlap (average %)  \n",
       "0                               79.79  \n",
       "1                               83.81  \n",
       "2                               82.82  \n",
       "3                               81.47  \n",
       "4                               70.62  \n",
       "5                               77.98  \n",
       "6                               81.14  \n",
       "7                               78.26  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Effect sizes\n",
    "effect_sizes_all = pd.read_csv(r\"\")\n",
    "display(effect_sizes_all['data_set'].unique())\n",
    "\n",
    "# % containing 0\n",
    "effect_sizes = effect_sizes_all[effect_sizes_all['data_set'] != 'data_online']\n",
    "effect_sizes_0 = effect_sizes[effect_sizes['d_lower']<=0]\n",
    "print(\"Percent of participant CIs containing 0: \", len(effect_sizes_0)/len(effect_sizes)*100, \"%\")\n",
    "print(\"In different samples:\")\n",
    "for data_set in effect_sizes['data_set'].unique():\n",
    "    df_temp = effect_sizes[effect_sizes['data_set']==data_set]\n",
    "    df_temp_0 = df_temp[df_temp['d_lower']<=0]\n",
    "    print(\"In\", data_set, \": \", len(df_temp_0)/len(df_temp)*100, \"%\")\n",
    "print(\"In different task versions:\")\n",
    "for trial_type in effect_sizes['trial_type'].unique():\n",
    "    df_temp = effect_sizes[effect_sizes['trial_type']==trial_type]\n",
    "    df_temp_0 = df_temp[df_temp['d_lower']<=0]\n",
    "    print(\"In\", trial_type, \": \", len(df_temp_0)/len(df_temp)*100, \"%\")\n",
    "\n",
    "# Overlap\n",
    "def percent_overlap(name, data):\n",
    "    ci = np.array(data[data['online ID']==name][['d_lower', 'd_higher']])[0]\n",
    "    \n",
    "    rest = data[data['online ID']!=name][['d_mean', 'd_lower', 'd_higher']]\n",
    "    rest['CI_overlap'] = np.where((rest['d_lower']>ci[1])|(rest['d_higher']<ci[0]),0,1)\n",
    "    rest['point_overlap'] = np.where((rest['d_mean']>ci[0])&(rest['d_mean']<ci[1]), 1, 0)\n",
    "\n",
    "    return(np.sum(rest['CI_overlap'])/len(rest)*100, np.sum(rest['point_overlap'])/len(rest)*100)\n",
    "\n",
    "overlap_results = pd.DataFrame(columns=['trial_type', 'data_frame', 'CI overlap (%)', 'point estimate overlap (%)'])\n",
    "for trial_type in effect_sizes_all['trial_type'].unique():\n",
    "    df_trial_type = effect_sizes_all[effect_sizes_all['trial_type']==trial_type]\n",
    "    for data_set in effect_sizes_all['data_set'].unique():\n",
    "        df_temp = df_trial_type[df_trial_type['data_set']==data_set]\n",
    "        ci_overlap_list = []\n",
    "        point_overlap_list = []\n",
    "        for name in df_temp['online ID']:\n",
    "            ci_overlap, point_overlap = percent_overlap(name, df_temp)\n",
    "            ci_overlap_list.append(ci_overlap)\n",
    "            point_overlap_list.append(point_overlap)\n",
    "        overlap_results.loc[len(overlap_results.index)] = [trial_type, data_set, np.mean(ci_overlap_list), np.mean(point_overlap_list)]\n",
    "\n",
    "display('Mean Ci overlap', np.mean(overlap_results[overlap_results['data_frame']!='data_online']['CI overlap (%)']), \n",
    "'Mean containing point estimate', np.mean(overlap_results[overlap_results['data_frame']!='data_online']['point estimate overlap (%)']))\n",
    "\n",
    "labels_dataset = {'data_mr_young':'MRI data (young)', 'data_online_young':'Online data (young)', \n",
    "                  'data_online_old':'Online data (old)', 'data_online':'Online data (all)'}\n",
    "version_dict = {'OBJ':'Object version', 'LOC':'Location version'}\n",
    "\n",
    "overlap_results['data_frame'] = [labels_dataset[name] for name in overlap_results['data_frame']]\n",
    "overlap_results['trial_type'] = [version_dict[name] for name in overlap_results['trial_type']]\n",
    "overlap_results.columns = ['Task version', 'Sample', 'CI overlap (average %)', 'Point estimate overlap (average %)']\n",
    "display(overlap_results.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "497338f01161d141240caa60efca5087225791fadc9b7c964beb65d863e046f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
